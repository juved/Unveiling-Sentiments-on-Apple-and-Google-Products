{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/jayiraj/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to /Users/jayiraj/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jayiraj/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, ConfusionMatrixDisplay\n",
    "\n",
    "# Notice that these vectorizers are from `sklearn` and not `nltk`!\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,\\\n",
    "HashingVectorizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('../data/judge-1377884607_tweet_product_company.csv', encoding='latin1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_text', 'emotion_in_tweet_is_directed_at',\n",
       "       'is_there_an_emotion_directed_at_a_brand_or_product'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
       "1       @jessedee Know about @fludapp ? Awesome iPad/i...\n",
       "2       @swonderlin Can not wait for #iPad 2 also. The...\n",
       "3       @sxsw I hope this year's festival isn't as cra...\n",
       "4       @sxtxstate great stuff on Fri #SXSW: Marissa M...\n",
       "                              ...                        \n",
       "9088                        Ipad everywhere. #SXSW {link}\n",
       "9089    Wave, buzz... RT @mention We interrupt your re...\n",
       "9090    Google's Zeiger, a physician never reported po...\n",
       "9091    Some Verizon iPhone customers complained their...\n",
       "9092    Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...\n",
       "Name: tweet_text, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion_in_tweet_is_directed_at'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "df = df.rename(columns={\n",
    "    'emotion_in_tweet_is_directed_at': 'products',\n",
    "    'is_there_an_emotion_directed_at_a_brand_or_product': 'emotions'\n",
    "})\n",
    "\n",
    "# Check the updated DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the value in the 'emotions' column\n",
    "df['emotions'] = df['emotions'].replace('No emotion toward brand or product', 'No emotion')\n",
    "\n",
    "# Check the updated distribution\n",
    "print(df['emotions'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the style for seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot the updated distribution of emotions\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='emotions', data=df)\n",
    "plt.title('Updated Distribution of Emotions Directed at a Brand or Product')\n",
    "plt.xlabel('Emotion Category')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the updated distribution of emotions\n",
    "plt.figure(figsize=(8, 6))\n",
    "#sns.countplot(x='products', data=df)\n",
    "sns.countplot(df['products'])\n",
    "plt.title('Updated Distribution of Emotions Directed at a Brand or Product')\n",
    "plt.xlabel('Emotion Category')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_text'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['products'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['products'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['products'].isna()].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_products = [\n",
    "    'iPhone',\n",
    "    'iPad',\n",
    "    'MacBook',\n",
    "    'iMac',\n",
    "    'Mac Mini',\n",
    "    'Apple Watch',\n",
    "    'AirPods',\n",
    "    'HomePod',\n",
    "]\n",
    "\n",
    "android_products = [\n",
    "    'Samsung Galaxy',\n",
    "    'Google Pixel',\n",
    "    'OnePlus',\n",
    "    'LG G series',\n",
    "    'Huawei P series',\n",
    "]\n",
    "\n",
    "# List of Google products\n",
    "google_products = [\n",
    "    'Google Pixel',\n",
    "    'Google Home',\n",
    "    'Google Nest',\n",
    "    'Chromecast',\n",
    "    'Pixelbook',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update products based on the tweet text\n",
    "def update_products(tweet_text):\n",
    "    if pd.notna(tweet_text):\n",
    "        if any(product.lower() in tweet_text.lower() for product in apple_products):\n",
    "            return 'Apple'\n",
    "        elif any(product.lower() in tweet_text.lower() for product in android_products):\n",
    "            return 'Android'\n",
    "        elif any(product.lower() in tweet_text.lower() for product in google_products):\n",
    "            return 'Google'\n",
    "    return pd.NA  # or any value you want for other cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['products'].isna()].head(50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#filter to dectect non ascci caracters and return boolean value in ascii\n",
    "df['ascii'] = df['tweet_text'].apply(lambda x: bool(re.search(r'[:;]-?[\\)DPO\\(]', str(x))))\n",
    "\n",
    "# Display the result\n",
    "print(df[['tweet_text', 'ascii']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ascii'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['ascii']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNaN = df[(df['products'].isna()) & (df['emotions'] == 'No emotion')].copy()\n",
    "\n",
    "# Display the new DataFrame\n",
    "dfNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the positive emoticons\n",
    "positive_emoticons = [\":')\", \"XP\", \"xD\", \"8)\", \":-P\", \"=]\", \":p\", \";P\", \":P\", \"XD\", \"(:\", \"=)\", \":]\", \";)\", \"=D\", \";-)\", \";D\", \":-D\", \":-)\", \":)\", \":D\"]\n",
    "\n",
    "# Define the negative emoticons\n",
    "negative_emoticons = [\":(\", \":'(\", \":-(\", \";(\", \">:(\", \":/\", \":-/\", \"D:\", \":\\\\\", \"DX\"]\n",
    "\n",
    "#create a new column new_e to test the column update\n",
    "dfNaN['new_e'] = None\n",
    "\n",
    "# Update 'new_e' based on positive and negative emoticons\n",
    "positive_pattern = '|'.join(map(re.escape, positive_emoticons))\n",
    "negative_pattern = '|'.join(map(re.escape, negative_emoticons))\n",
    "\n",
    "# Use fillna to replace NaN values in 'tweet_text' with an empty string\n",
    "dfNaN['tweet_text'] = dfNaN['tweet_text'].fillna('')\n",
    "\n",
    "dfNaN.loc[dfNaN['tweet_text'].str.contains(positive_pattern), 'new_e'] = 'Positive emotion'\n",
    "dfNaN.loc[dfNaN['tweet_text'].str.contains(negative_pattern), 'new_e'] = 'Negative emotion'\n",
    "\n",
    "# Display the updated DataFrame\n",
    "dfNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import regex as re\n",
    "\n",
    "# Function to check if a text contains miscellaneous characters\n",
    "def contains_misc_characters(text):\n",
    "    if isinstance(text, str):\n",
    "        pattern = re.compile(r'[\\x00-\\x7F]+')  # Matches non-ASCII characters\n",
    "        return not pattern.match(text)\n",
    "    return False\n",
    "\n",
    "# Apply the function to each line in the 'tweet_text' column and create a new 'tweet_misc' column\n",
    "df['tweet_misc'] = df['tweet_text'].apply(contains_misc_characters)\n",
    "\n",
    "# Display the result\n",
    "print(df[['tweet_text', 'tweet_misc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_misc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['tweet_misc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['products'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
